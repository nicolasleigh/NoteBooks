**1.1 What Is the Internet?**

The Internet is a computer network that interconnects billions of computing devices throughout the world. Given the many nontraditional devices that are being hooked up to the Internet, the term computer network is beginning to sound a bit dated. In Internet jargon, all of these devices are called **hosts** or **end systems**.

> In networking jargon, a computer, phone, or [Internet of Things](https://en.wikipedia.org/wiki/Internet_of_things) device connected to a [computer network](https://en.wikipedia.org/wiki/Computer_network) is sometimes referred to as an **end system** or **end station**, because it sits at the edge of the network. The [end user](https://en.wikipedia.org/wiki/End_user) directly interacts with an end system that provides information or services.
>
> End systems that are connected to the Internet are also referred to as [Internet hosts](https://en.wikipedia.org/wiki/Internet_host); this is because they host (run) [Internet applications](https://en.wikipedia.org/wiki/Rich_web_application) such as [web browsers](https://en.wikipedia.org/wiki/Web_browser) or [mail servers](https://en.wikipedia.org/wiki/Mail_server).

End systems are connected together by a network of **communication links** and **packet switches**. There are many types of communication links, which are made up of different types of **physical media**, including **coaxial cable**, **copper wire**, **optical fiber**, and **radio spectrum**. Different links can transmit data at different rates, with the transmission rate of a link measured in bits/second.

> **Physical media** refers to the physical materials that are used to store or transmit information in [data communications](https://en.wikipedia.org/wiki/Data_communications). These physical media are generally physical objects made of materials such as [copper](https://en.wikipedia.org/wiki/Copper) or [glass](https://en.wikipedia.org/wiki/Glass).
>
> **Coaxial cable**, or **coax** (pronounced [/ˈkoʊ.æks/](https://en.wikipedia.org/wiki/Help:IPA/English)), is a type of [electrical cable](https://en.wikipedia.org/wiki/Electrical_cable) consisting of an inner [conductor](https://en.wikipedia.org/wiki/Electrical_conductor) surrounded by a concentric conducting [shield](https://en.wikipedia.org/wiki/Electromagnetic_shielding), with the two separated by a [dielectric](https://en.wikipedia.org/wiki/Dielectric) ([insulating](<https://en.wikipedia.org/wiki/Insulator_(electricity)>) material); many coaxial cables also have a protective outer sheath or jacket. The term _[coaxial](https://en.wikipedia.org/wiki/Coaxial)_ refers to the inner conductor and the outer shield sharing a geometric axis.
>
> ![Coaxial cable](https://upload.wikimedia.org/wikipedia/commons/f/f4/Coaxial_cable_cutaway.svg)
>
> A **copper wire** is a single [electrical conductor](https://simple.wikipedia.org/wiki/Electrical_conductor) made of copper. It can be [insulated](<https://simple.wikipedia.org/wiki/Insulator_(electricity)>) or uninsulated. A **copper cable** is a group of two or more copper [wires](https://simple.wikipedia.org/wiki/Wire) bundled together in a single sheath or jacket.
>
> An **optical fiber**, or **optical fibre**, is a flexible [glass](https://en.wikipedia.org/wiki/Glass) or plastic [fiber](https://en.wikipedia.org/wiki/Fiber) that can transmit light from one end to the other.
>
> The **radio spectrum** is part of the [electromagnetic spectrum](https://en.wikipedia.org/wiki/Electromagnetic_spectrum) with [frequencies](https://en.wikipedia.org/wiki/Frequency) from 3 [Hz](https://en.wikipedia.org/wiki/Hertz) to 3,000 [GHz](https://en.wikipedia.org/wiki/Hertz) (3 [THz](https://en.wikipedia.org/wiki/Hertz)). Electromagnetic waves in this frequency range, called [radio waves](https://en.wikipedia.org/wiki/Radio_wave), are widely used in modern technology, particularly in [telecommunication](https://en.wikipedia.org/wiki/Telecommunication).

When one end system has data to send to another end system, the sending end system segments the data and adds header bytes to each segment. The resulting packages of information, known as **packets** in the jargon of computer networks, are then sent through the network to the destination end system, where they are reassembled into the original data.

> a **network packet** is a formatted unit of [data](<https://en.wikipedia.org/wiki/Data_(computing)>) carried by a [packet-switched network](https://en.wikipedia.org/wiki/Packet-switched_network). A packet consists of control information and user data; the latter is also known as the _[payload](<https://en.wikipedia.org/wiki/Payload_(computing)>)\_. Control information provides data for delivering the payload (e.g., source and destination [network addresses](https://en.wikipedia.org/wiki/Network_address), [error detection](https://en.wikipedia.org/wiki/Error_detection) codes, or sequencing information).

A **packet switch** takes a packet arriving on one of its incoming **communication links** and forwards that packet to one of its outgoing communication links. The two most prominent packet switches in today’s Internet are **routers** and **link-layer switches**. Both types of switches forward packets toward their ultimate destinations. Link-layer switches are typically used in **access networks**, while routers are typically used in the **network core**. The sequence of communication links and packet switches traversed by a packet from the sending end system to the receiving end system is known as a **route** or **path** through the network.

> Access networks are the communication networks that connect end-user devices, such as computers, smartphones, and tablets, to a wide area network ([WAN](https://www.techtarget.com/searchnetworking/definition/WAN-wide-area-network)), such as the Internet.
>
> A **backbone** or **core network** is a part of a [computer network](https://en.wikipedia.org/wiki/Computer_network) which interconnects networks, providing a path for the exchange of information between different [LANs](https://en.wikipedia.org/wiki/LAN) or [subnetworks](https://en.wikipedia.org/wiki/Subnetwork).

Thus, in many ways, packets are analogous to trucks, communication links are analogous to highways and roads, packet switches are analogous to intersections, and end systems are analogous to buildings. Just as a truck takes a path through the transportation network, a packet takes a path through a computer network.

End systems access the Internet through **Internet Service Providers** (ISPs), including residential ISPs such as local cable or telephone companies; corporate ISPs; university ISPs; ISPs that provide WiFi access in airports, hotels, coffee shops, and other public places; and cellular data ISPs, providing mobile access to our smartphones and other devices.

ISPs provide a variety of types of network access to the end systems, including residential **broadband** access such as cable modem or DSL, high-speed local area network access, and mobile wireless access. ISPs also provide Internet access to content providers, connecting servers directly to the Internet. The Internet is all about connecting end systems to each other, so the ISPs that provide access to end systems must also be interconnected. These lower-tier ISPs are thus interconnected through national and international upper-tier ISPs and these upper-tier ISPs are connected directly to each other.

> In telecommunications, a broadband signaling method is one that handles a wide band of frequencies. "Broadband" is a relative term, understood according to its context. The wider (or broader) the bandwidth of a channel, the greater the data-carrying capacity, given the same channel quality. In the context of [Internet access](https://en.wikipedia.org/wiki/Internet_access), the term "broadband" is used loosely to mean "access that is always on and faster than the traditional dial-up access".
>
> **Bandwidth** is the difference between the upper and lower [frequencies](https://en.wikipedia.org/wiki/Frequency) in a continuous [band of frequencies](https://en.wikipedia.org/wiki/Frequency_band). It is typically measured in [unit](https://en.wikipedia.org/wiki/Unit_of_measurement) of [hertz](https://en.wikipedia.org/wiki/Hertz) (symbol Hz).

The Transmission Control Protocol (TCP) and the Internet Protocol (IP) are two of the most important **protocols** in the Internet.

> A network protocol is an established set of rules that determine how data is transmitted between different devices in the same network. Essentially, it allows connected devices to communicate with each other, regardless of any differences in their internal processes, structure or design.

All activity in the Internet that involves two or more communicating remote entities is governed by a protocol. For example, hardware-implemented protocols in two physically connected computers control the flow of bits on the “wire” between the two **network interface cards**; congestion-control protocols in end systems control the rate at which packets are transmitted between sender and receiver; protocols in routers determine a packet’s path from source to destination.

> A **network interface controller** (**NIC**, also known as a **network interface card**, **network adapter**, **LAN adapter**, and **physical network interface**) is a [computer hardware](https://en.wikipedia.org/wiki/Computer_hardware) component that connects a [computer](https://en.wikipedia.org/wiki/Computer) to a [computer network](https://en.wikipedia.org/wiki/Computer_network). Network interface controllers were originally implemented as expansion cards that plugged into a computer bus. The low cost and ubiquity of the Ethernet standard mean that most new computers have a network interface controller built into the motherboard.

---

**1.2 The Network Edge**

Hosts are sometimes further divided into two categories: clients and servers. Informally, clients tend to be desktops, laptops, smartphones, and so on, whereas servers tend to be more powerful machines that store and distribute Web pages, stream video, relay e-mail, and so on. Today, most of the servers from which we receive search results, e-mail, Web pages, videos and mobile app content reside in large data centers.

Today, the two most prevalent types of broadband residential access are **digital subscriber line** (**DSL**) and **cable**. A residence typically obtains DSL Internet access from the same local telephone company (telco) that provides its wired local phone access. Thus, when DSL is used, a customer’s telco is also its ISP. Each customer’s DSL modem uses the existing telephone line exchange data with a **digital subscriber line access multiplexer** (**DSLAM**) located in the telco’s local central office (CO). The home’s DSL modem takes digital data and translates it to high-frequency tones for transmission over telephone wires to the CO; the analog signals from many such houses are translated back into digital format at the DSLAM.

> **Digital subscriber line** (**DSL**; originally **digital subscriber loop**) is a family of technologies that are used to transmit [digital data](https://en.wikipedia.org/wiki/Digital_data) over [telephone lines](https://en.wikipedia.org/wiki/Telephone_line). In telecommunications marketing, the term DSL is widely understood to mean [asymmetric digital subscriber line](https://en.wikipedia.org/wiki/Asymmetric_digital_subscriber_line) (ADSL), the most commonly installed DSL technology, for [Internet access](https://en.wikipedia.org/wiki/Internet_access). In ADSL, the data throughput in the [upstream](<https://en.wikipedia.org/wiki/Upstream_(networking)>) direction (the direction to the service provider) is lower, hence the designation of _asymmetric_ service.
>
> A DSL modem uses a phone line to connect to the Internet, while a cable modem uses a cable TV line. One of the main difference between DSL modem and cable modem is that a DSL modem uses your home’s existing copper phone line while a cable modem uses a coaxial cable line.
>
> - [Difference between DSL Modem and Cable Modem](https://www.tutorialspoint.com/difference-between-dsl-modem-and-cable-modem)
> - [DSL vs. Cable – Internet Connection Comparison Guide](https://www.xfinity.com/hub/internet/dsl-vs-cable)
> - [DSL vs Cable - Cable Modem vs DSL for Business Applications](https://www.mushroomnetworks.com/blog/cable-modem-vs-dsl-business-applications/)
>
> A **digital subscriber line access multiplexer** (**DSLAM**, often pronounced _DEE-slam_) is a network device, often located in [telephone exchanges](https://en.wikipedia.org/wiki/Telephone_exchange), that connects multiple customer [digital subscriber line](https://en.wikipedia.org/wiki/Digital_subscriber_line) (DSL) interfaces to a high-speed digital communications channel using [multiplexing](https://en.wikipedia.org/wiki/Multiplexing) techniques.

While DSL makes use of the telco’s existing local telephone infrastructure, cable Internet access makes use of the cable television company’s existing cable television infrastructure. Fiber optics connect the **cable television headend** to neighborhood-level junctions, from which traditional **coaxial cable** is then used to reach individual houses and apartments. Each neighborhood junction typically supports 500 to 5,000 homes. Because both fiber and coaxial cable are employed in this system, it is often referred to as **hybrid fiber coax** (**HFC**).

**Cable internet access** requires special modems, called **cable modems**. As with a DSL modem, the cable modem is typically an external device and connects to the home PC through an Ethernet port. At the cable headend, the **cable modem termination system** (**CMTS**) serves a similar function as the DSL network’s DSLAM—turning the analog signal sent from the cable modems in many downstream homes back into digital format. Cable modems divide the HFC network into two channels, a downstream and an upstream channel. As with DSL, access is typically asymmetric, with the downstream channel typically allocated a higher transmission rate than the upstream channel.

> A **cable modem termination system** (**CMTS**, also called a **CMTS Edge Router**) is a piece of [equipment](https://en.wikipedia.org/wiki/Equipment_rental), typically [located](https://en.wikipedia.org/wiki/Located) in a cable company's [headend](https://en.wikipedia.org/wiki/Cable_television_headend), which is used to provide data [services](https://en.wikipedia.org/wiki/Network_service), such as [cable Internet](https://en.wikipedia.org/wiki/Cable_modem) or [Voice over IP](https://en.wikipedia.org/wiki/Voice_over_IP), to cable subscribers. A CMTS provides many of the same functions provided by the [DSLAM](https://en.wikipedia.org/wiki/DSLAM) in a [DSL](https://en.wikipedia.org/wiki/Digital_subscriber_line) system.

One important characteristic of **cable Internet access** is that it is a shared broadcast medium. In particular, every packet sent by the headend travels downstream on every link to every home and every packet sent by a home travels on the upstream channel to the headend. For this reason, if several users are simultaneously downloading a video file on the downstream channel, the actual rate at which each user receives its video file will be significantly lower than the aggregate cable downstream rate. On the other hand, if there are only a few active users and they are all Web surfing, then each of the users may actually receive Web pages at the full cable downstream rate, because the users will rarely request a Web page at exactly the same time. Because the upstream channel is also shared, a distributed multiple access protocol is needed to coordinate transmissions and avoid collisions.

Although DSL and cable networks currently represent the majority of residential broadband access, an up-and-coming technology that provides even higher speeds is fiber to the home (FTTH). As the name suggests, the FTTH concept is simple—provide an optical fiber path from the central office(CO) directly to the home. FTTH can potentially provide Internet access rates in the gigabits per second range.

---

**1.3 The Network Core**

Store-and-forward transmission means that the packet switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link.

Each packet switch has multiple links attached to it. For each attached link, the packet switch has an **output buffer** (also called an **output queue**), which stores packets that the router is about to send into that link. The output buffers play a key role in packet switching. If an arriving packet needs to be transmitted onto a link but finds the link busy with the transmission of another packet, the arriving packet must wait in the output buffer. Thus, in addition to the **store-and-forward delays**, packets suffer output buffer **queuing delays**.

> In a [network](https://en.wikipedia.org/wiki/Computer_network) based on [packet switching](https://en.wikipedia.org/wiki/Packet_switching), **transmission delay** (or **store-and-forward delay**, also known as **packetization delay** or **serialization delay**) is the amount of time required to push all the packet's bits into the wire. In other words, this is the delay caused by the data-rate of the link. Transmission delay is a function of the packet's length and has nothing to do with the distance between the two nodes. This delay is proportional to the packet's length in bits.

Since the amount of buffer space is finite, an arriving packet may find that the buffer is completely full with other packets waiting for transmission. In this case, packet loss will occur—either the arriving packet or one of the already-queued packets will be dropped.

Each router has a forwarding table that maps destination addresses (or portions of the destination addresses) to that router’s outbound links. When a packet arrives at a router, the router examines the address and searches its forwarding table, using this destination address, to find the appropriate outbound link. The router then directs the packet to this outbound link.

The Internet has a number of special routing protocols that are used to automatically set the forwarding tables. A routing protocol may, for example, determine the shortest path from each router to each destination and use the shortest path results to configure the forwarding tables in the routers.

There are two fundamental approaches to moving data through a network of links and switches: **circuit switching** and **packet switching**. In **circuit-switched networks**, the resources needed along a path (buffers, link transmission rate) to provide for communication between the end systems are _reserved_ for the duration of the communication session between the end systems. In **packet-switched networks**, these resources are _not_ reserved; a session’s messages use the resources on demand and, as a consequence, may have to wait (that is, queue) for access to a communication link. As a simple analogy, consider two restaurants, one that requires reservations and another that neither requires reservations nor accepts them. For the restaurant that requires reservations, we have to go through the hassle of calling before we leave home. But when we arrive at the restaurant we can, in principle, immediately be seated and order our meal. For the restaurant that does not require reservations, we don’t need to bother to reserve a table. But when we arrive at the restaurant, we may have to wait for a table before we can be seated.

Traditional telephone networks are examples of **circuit-switched networks**. Consider what happens when one person wants to send information (voice or facsimile) to another over a telephone network. Before the sender can send the information, the network must establish a connection between the sender and the receiver. In the jargon of telephony, this connection is called a circuit. When the network establishes the circuit, it also reserves a constant transmission rate in the network’s links for the duration of the connection.

> It contrasts with packet-switched networks, which break the communication into packets and then send those packets through the network independently of one another. They do not establish a dedicated communications channel between hosts, rather they offer a “best effort” network that can be used by a variety of hosts to communicate at the same time.

A circuit in a link is implemented with either **frequency-division multiplexing** (**FDM**) or **time-division multiplexing** (**TDM**).

> In [telecommunications](https://en.wikipedia.org/wiki/Telecommunications), **frequency-division multiplexing** (**FDM**) is a technique by which the total [bandwidth](<https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)>) available in a [communication medium](https://en.wikipedia.org/wiki/Communication_channel) is divided into a series of non-overlapping [frequency bands](https://en.wikipedia.org/wiki/Frequency_bands), each of which is used to carry a separate signal. This allows a single transmission medium such as a microwave radio link, cable or [optical fiber](https://en.wikipedia.org/wiki/Optical_fiber) to be shared by multiple independent signals.
>
> In frequency division multiplexing all the signals operate at the same time with different frequencies, but in time-division multiplexing, all the signals operate with the same frequency at different times.

For a TDM link, time is divided into frames of fixed duration, and each frame is divided into a fixed number of time slots. When the network establishes a connection across a link, the network dedicates one time slot in every frame to this connection. These slots are dedicated for the sole use of that connection, with one time slot available for use (in every frame) to transmit the connection’s data.

> - [Packet-Switched Network vs. Circuit-Switched Network: Understanding the 15 Key Differences](https://www.spiceworks.com/tech/networking/articles/packet-switched-vs-circuit-switched-network/)
> - [Circuit Switching in Computer Networks: A Comprehensive Guide](https://dev.to/m__mdy__m/circuit-switching-in-computer-networks-a-comprehensive-guide-1o29)

Today’s Internet—a network of networks—is complex, consisting of a dozen or so tier-1 ISPs and hundreds of thousands of lower-tier ISPs. The ISPs are diverse in their coverage, with some spanning multiple continents and oceans, and others limited to narrow geographic regions. The lower-tier ISPs connect to the higher-tier ISPs, and the higher-tier ISPs interconnect with one another.

---

**1.4 Delay, Loss, and Throughput in Packet-Switched Networks**

In packet-switched networks, the packet suffers from several types of delays at _each_ node along the path. The most important of these delays are the **nodal processing delay**, **queuing delay**, **transmission delay**, and **propagation delay**; together, these delays accumulate to give a **total nodal delay**.

The time required to examine the packet’s header and determine where to direct the packet is part of the **processing delay**.

At the queue, the packet experiences a **queuing delay** as it waits to be transmitted onto the link. The length of the queuing delay of a specific packet will depend on the number of earlier-arriving packets that are queued and waiting for transmission onto the link.

Assuming that packets are transmitted in a first-come-first-served manner, as is common in packet-switched networks, our packet can be transmitted only after all the packet's bits have arrived. The **transmission delay** is L/R. This is the amount of time required to push (that is, transmit) all of the packet’s bits into the link.

Once a bit is pushed into the link, it needs to propagate to router B. The time required to propagate from the beginning of the link to router B is the **propagation delay**. The bit propagates at the propagation speed of the link. The **propagation speed** depends on the physical medium of the link (that is, fiber optics, twisted-pair copper wire, and so on) and is in the range of $2\bullet10^8$ meters/sec to $3\bullet10^8$ meters/sec, which is equal to, or a little less than, the speed of light. The propagation delay is the distance between two routers divided by the propagation speed.

The **transmission delay** is the amount of time required for the router to push out the packet; it is a function of the packet’s length and the transmission rate of the link, but has nothing to do with the distance between the two routers. The **propagation delay**, on the other hand, is the time it takes a bit to propagate from one router to the next; it is a function of the distance between the two routers, but has nothing to do with the packet’s length or the transmission rate of the link.

The most complicated and interesting component of nodal delay is the queuing delay. In fact, queuing delay is so important and interesting in computer networking that thousands of papers and numerous books have been written about it. Unlike the other three delays, the queuing delay can vary from packet to packet.

When is the **queuing delay** large and when is it insignificant? The answer to this question depends on the rate at which traffic arrives at the queue, the transmission rate of the link, and the nature of the arriving traffic, that is, whether the traffic arrives periodically or arrives in bursts. To gain some insight here, let _a_ denote the average rate at which packets arrive at the queue (_a_ is in units of packets/sec). Recall that _R_ is the **transmission rate**; that is, it is the rate (in bits/sec) at which bits are pushed out of the queue. Also suppose, for simplicity, that all packets consist of _L_ bits. Then the average rate at which bits arrive at the queue is _La_ bits/sec. Finally, assume that the queue is very big, so that it can hold essentially an infinite number of bits. The ratio _La/R_, called the **traffic intensity**, often plays an important role in estimating the extent of the **queuing delay**. If _La/R_ > 1, then the average rate at which bits arrive at the queue exceeds the rate at which the bits can be transmitted from the queue. In this unfortunate situation, the queue will tend to increase without bound and the **queuing delay** will approach infinity! Therefore, one of the golden rules in traffic engineering is: _Design your system so that the **traffic intensity** is no greater than 1._

Now consider the case _La/R_ ≤ 1. Here, the nature of the arriving traffic impacts the **queuing delay**. For example, if packets arrive periodically—that is, one packet arrives every _L/R_ seconds—then every packet will arrive at an empty queue and there will be no queuing delay. On the other hand, if packets arrive in bursts but periodically, there can be a significant average queuing delay. For example, suppose _N_ packets arrive simultaneously every _(L/R)N_ seconds. Then the first packet transmitted has no queuing delay; the second packet transmitted has a queuing delay of I seconds; and more generally, the nth packet transmitted has a queuing delay of _(n - 1)L/R_ seconds.

Because the **queue capacity** is finite, packet delays do not really approach infinity as the traffic intensity approaches 1. Instead, a packet can arrive to find a full queue. With no place to store such a packet, a router will drop that packet; that is, the packet will be lost. From an end-system viewpoint, a packet loss will look like a packet having been transmitted into the network core but never emerging from the network at the destination. The fraction of lost packets increases as the **traffic intensity** increases. Therefore, performance at a node is often measured not only in terms of delay, but also in terms of the probability of packet loss.

In addition to delay and packet loss, another critical performance measure in computer networks is end-to-end throughput. For the simple two-link network, the throughput is min{$R_c,R_s$}, that is, it is the transmission rate of the bottleneck link.

**Throughput** depends on the **transmission rates** of the links over which the data flows. When there is no other intervening traffic, the throughput can simply be approximated as the minimum transmission rate along the path between source and destination. More generally the throughput depends not only on the transmission rates of the links along the path, but also on the intervening traffic. In particular, a link with a high transmission rate may nonetheless be the bottleneck link for a file transfer if many other data flows are also passing through that link.

---

**1.5 Protocol Layers and Their Service Models**

A protocol layer can be implemented in software, in hardware, or in a combination of the two. Application-layer protocols—such as HTTP and SMTP—are almost always implemented in software in the end systems; so are transport-layer protocols. Because the physical layer and data link layers are responsible for handling communication over a specific link, they are typically implemented in a **network interface card** (for example, Ethernet or WiFi interface cards) associated with a given link. The network layer is often a mixed implementation of hardware and software.

One potential drawback of layering is that one layer may duplicate lower-layer functionality. For example, many protocol stacks provide error recovery on both a per-link basis and an end-to-end basis. A second potential drawback is that functionality at one layer may need information (for example, a timestamp value) that is present only in another layer; this violates the goal of separation of layers.

Link-layer switches implement layers 1 and 2, routers implement layers 1 through 3. This means, for example, that Internet routers are capable of implementing the IP protocol (a layer 3 protocol), while link-layer switches are not. While link-layer switches do not recognize IP addresses, they are capable of recognizing layer 2 addresses, such as Ethernet addresses. Note that hosts implement all five layers, this is because the Internet architecture puts much of its complexity at the edges of the network.

---

**1.6 Networks Under Attack**

Another broad class of security threats is known as **denial-of-service** (**DoS**) attacks. As the name suggests, a **DoS** attack renders a network, host, or other piece of infrastructure unusable by legitimate users. Most Internet **DoS** attacks fall into one of three categories:

- Vulnerability attack. This involves sending a few well-crafted messages to a vulnerable application or operating system running on a targeted host. If the right sequence of packets is sent to a vulnerable application or operating system, the service can stop or, worse, the host can crash.
- Bandwidth flooding. The attacker sends a deluge of packets to the targeted host—so many packets that the target’s access link becomes clogged, preventing legitimate packets from reaching the server.
- Connection flooding. The attacker establishes a large number of half-open or fully-open TCP connections at the target host. The host can become so bogged down with these bogus connections that it stops accepting legitimate connections.

If the server has an access rate of _R_ bps, then the attacker will need to send traffic at a rate of approximately _R_ bps to cause damage. If _R_ is very large, a single attack source may not be able to generate enough traffic to harm the server. Furthermore, if all the traffic emanates from a single source, an upstream router may be able to detect the attack and block all traffic from that source before the traffic gets near the server. In a **distributed DoS** (**DDoS**) attack, the attacker controls multiple sources and has each source blast traffic at the target. With this approach, the aggregate traffic rate across all the controlled sources needs to be approximately _R_ to cripple the service. **DDoS** attacks leveraging **botnets** with thousands of comprised hosts are a common occurrence today. DDoS attacks are much harder to detect and defend against than a DoS attack from a single host.

A passive receiver that records a copy of every packet that flies by is called a **packet sniffer**. Because packet sniffers are passive—that is, they do not inject packets into the channel—they are difficult to detect. So, when we send packets into a wireless channel, we must accept the possibility that some bad guy may be recording copies of our packets. As you may have guessed, some of the best defenses against packet sniffing involve cryptography.

It is surprisingly easy to create a packet with an arbitrary source address, packet content, and destination address and then transmit this hand-crafted packet into the Internet, which will dutifully forward the packet to its destination. The ability to inject packets into the Internet with a false source address is known as **IP spoofing**, and is but one of many ways in which one user can masquerade as another user. To solve this problem, we will need end-point authentication, that is, a mechanism that will allow us to determine with certainty if a message originates from where we think it does.
