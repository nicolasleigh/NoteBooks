## Building, Versioning and Quality Control

### Creating and Using Makefiles

#### A simple makefile

**Important**: Please note that each command in a makefile rule must start with a tab character, not spaces.

```makefile
# File: Makefile 

run:  
	go run ./cmd/api
```

Call `make run` to start the API:

```
$ make run
```

By default `make` echoes commands in the terminal output. If you want, it’s possible to suppress commands from being echoed by prefixing them with the `@` character.

#### Environment variables

When we execute a `make` rule, every environment variable that is available to `make` when it starts is transformed into a make variable with the same name and value. We can then access these variables using the syntax `${VARIABLE_NAME}` in our makefile.

To illustrate this, let’s create two additional rules — a `psql` rule for connecting to our database and an `up` rule to execute our database migrations.

```makefile
# File: Makefile 

run:  
	go run ./cmd/api 	
	
psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
up: 
	@echo 'Running up migrations...' 
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up
```

#### Passing arguments

```makefile
# File: Makefile 

run:  
	go run ./cmd/api 
	
psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
migration:  
	@echo 'Creating migration files for ${name}...'  
	migrate create -seq -ext=.sql -dir=./migrations ${name} 
	
up:  
	@echo 'Running up migrations...'  
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up
```

And you can execute this new rule with the `name=create_example_table` argument:

```sh
$ make migration name=create_example_table
```

#### Namespacing targets

As your makefile continues to grow, you might want to start namespacing your target names to provide some differentiation between rules and help organize the file. For example, in a large makefile rather than having the target name `up` it would be clearer to give it the name `db/migrations/up` instead. 

I recommend using the `/` character as a namespace separator, rather than a period, hyphen or the `:` character. In fact, the `:` character should be strictly avoided in target names as it can cause problems when using **target prerequisites**.

```makefile
# File: Makefile 

run/api:  
	go run ./cmd/api 
	
db/psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
db/migrations/new:  
	@echo 'Creating migration files for ${name}...'  
	migrate create -seq -ext=.sql -dir=./migrations ${name} 
	
db/migrations/up:  
	@echo 'Running up migrations...'  
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up
```

A nice feature of using the `/` character as the namespace separator is that you get tab completion in the terminal when typing target names.

#### Prerequisite targets and asking for confirmation

```makefile
target: prerequisite-target-1 prerequisite-target-2 ...
	command  
	command  
	...
```

When you specify a prerequisite target for a rule, the corresponding commands for the prerequisite targets will be run before executing the actual target commands.

```makefile
# File: Makefile 

# Create the new confirm target.
confirm:  
	@echo 'Are you sure? [y/N] ' && read ans && [ $${ans:-N} = y ] 
	
run/api:  
	go run ./cmd/api 
	
db/psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
db/migrations/new:  
	@echo 'Creating migration files for ${name}...'  
	migrate create -seq -ext=.sql -dir=./migrations ${name} 
	
# Include it as prerequisite.
db/migrations/up: confirm  
	@echo 'Running up migrations...'  
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up
```

The code in the confirm target is taken from [this StackOverflow post](https://stackoverflow.com/questions/47837071/making-make-clean-ask-for-confirmation/47839479#47839479).

#### Displaying help information

Another small thing that we can do to make our makefile more user-friendly is to include some comments and help functionality. Specifically, we’ll prefix each rule in our makefile with a comment in the following format:

```
## <example target call>: <help text>
```

Then we’ll create a new `help` rule which parses the makefile itself, extracts the help text from the comments using [sed](https://www.gnu.org/software/sed/manual/sed.html), formats them into a table and then displays them to the user.

```makefile
# File: Makefile 

## help: print this help message 
help:  
	@echo 'Usage:' 
	@sed -n 's/^##//p' ${MAKEFILE_LIST} | column -t -s ':' 
	
confirm:  
	@echo 'Are you sure? [y/N] ' && read ans && [ $${ans:-N} = y ] 
	
## run/api: run the cmd/api application 
run/api:  
	go run ./cmd/api 
	
## db/psql: connect to the database using psql 
db/psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
## db/migrations/new name=$1: create a new database migration 
db/migrations/new:  
	@echo 'Creating migration files for ${name}...'  
	migrate create -seq -ext=.sql -dir=./migrations ${name} 
	
## db/migrations/up: apply all up database migrations 
db/migrations/up: confirm  
	@echo 'Running up migrations...'  
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up
```

**Note**: `MAKEFILE_LIST` is a [special variable](https://www.gnu.org/software/make/manual/html_node/Special-Variables.html) which contains the name of the makefile being parsed by make.

```
$ make help

Usage:
 help                        print this help message 
 run/api                     run the cmd/api application 
 db/psql                     connect to the database using psql 
 db/migrations/new name=$1   create a new database migration 
 db/migrations/up            apply all up database migrations 
```

I should also point out that positioning the help rule as the first thing in the Makefile is a deliberate move. If you run make without specifying a target then it will default to executing the first rule in the file.

#### Phony targets

In this chapter we’ve been using `make` to execute actions, but another (and arguably, the primary) purpose of `make` is to help create files on disk where the name of a target is the name of a file being created by the rule. 

If you’re using `make` primarily to execute actions, like we are, then this can cause a problem if there is a file in your project directory with the same path as a target name. 

If you want, you can demonstrate this problem by creating a file called `./run/api` in the root of your project directory, like so:

```sh
$ mkdir run && touch run/api
```

And then if you execute `make run/api`, instead of our API application starting up you’ll get the following message:

```
$ make run/api

make: `run/api' is up to date.
```

Because we already have a file on disk at `./run/api`, the `make` tool considers this rule to have already been executed and so returns the message that we see above without taking any further action.

To work around this, we can declare our makefile targets to be phony targets:

> A phony target is one that is not really the name of a file; rather it is just a name for a rule to be executed.

To declare a target as phony, you can make it prerequisite of the special `.PHONY` target. The syntax looks like this:

```
.PHONY: target 
target: prerequisite-target-1 prerequisite-target-2 ...
	command 
	command  
	...
```

Let’s go ahead and update out `Makefile` so that all our rules have phony targets, like so:

```makefile
# File: Makefile 

## help: print this help message 
.PHONY: help
help:  
	@echo 'Usage:' 
	@sed -n 's/^##//p' ${MAKEFILE_LIST} | column -t -s ':' 
	
.PHONY: confirm
confirm:  
	@echo 'Are you sure? [y/N] ' && read ans && [ $${ans:-N} = y ] 
	
## run/api: run the cmd/api application 
.PHONY: run/api
run/api:  
	go run ./cmd/api 
	
## db/psql: connect to the database using psql 
.PHONY: db/psql
db/psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
## db/migrations/new name=$1: create a new database migration 
.PHONY: db/migrations/new
db/migrations/new:  
	@echo 'Creating migration files for ${name}...'  
	migrate create -seq -ext=.sql -dir=./migrations ${name} 
	
## db/migrations/up: apply all up database migrations 
.PHONY: db/migrations/up
db/migrations/up: confirm  
	@echo 'Running up migrations...'  
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up
```

If you run `make run/api` again now, it should now correctly recognize this as a phony target and execute the rule for us:

```
$ make run/api

go run ./cmd/api 
time=2024-12-08T17:30:20.219+08:00 level=INFO msg="database connection pool established"
time=2024-12-08T17:30:20.219+08:00 level=INFO msg="starting server" addr=:4000 env=development
```

You might think that it’s only necessary to declare targets as phony if you have a conflicting file name, but in practice not declaring a target as phony when it actually is can lead to bugs or confusing behavior. For example, imagine if in the future someone unknowingly creates a file called `confirm` in the root of the project directory. This would mean that our `confirm` rule is never executed, which in turn would lead to dangerous or destructive rules being executed without confirmation. 

To avoid this kind of bug, if you have a makefile rule which carries out an action (rather than creating a file) then it’s best to get into the habit of declaring it as phony.

### Managing Environment Variables

Using the `make run/api` command to run our API application opens up an opportunity to tweak our command-line flags, and remove the default value for our database DSN from the `main.go` file. Like so:

```go
// File: cmd/api/main.go 

package main 

...

func main() {  
  var cfg config  
  
  flag.IntVar(&cfg.port, "port", 4000, "API server port")  
  flag.StringVar(&cfg.env, "env", "development", "Environment (development|staging|production)")  
  
  // Use the empty string "" as the default value for the db-dsn command-line flag, 
  // rather than os.Getenv("GREENLIGHT_DB_DSN") like we were previously.
  flag.StringVar(&cfg.db.dsn, "db-dsn", "", "PostgreSQL DSN")  
  
  ...
  
}
```

Instead, we can update our makefile so that the DSN value from the `GREENLIGHT_DB_DSN` environment variable is passed in as part of the rule.

```makefile
# File: Makefile 

...

## run/api: run the cmd/api application 
.PHONY: run/api 
run/api:  
	@go run ./cmd/api -db-dsn=${GREENLIGHT_DB_DSN} 
	
...
```

This is a small change but a really nice one, because it means that the default configuration values for our application no longer change depending on the operating environment. The command-line flag values passed at runtime are the sole mechanism for configuring our application settings, and there are still no secrets hard-coded in our project files.

### Quality Controlling Code

In this chapter we’re going to add new `audit` and `tidy` rules to our `Makefile` to check, test and tidy up our codebase automatically.

The `audit` rule won’t make any changes to our codebase, but will simply report any problems. In particular it will:

- Use the `go mod verify` command to check that the dependencies on your computer (located in your module cache located at `$GOPATH/pkg/mod`) haven’t been changed since they were downloaded and that they match the cryptographic hashes in your `go.sum` file. Running this helps ensure that the dependencies being used are the exact ones that you expect.
- Use the `go vet ./...` command to check all `.go` files in the project directory. The `go vet` tool runs a variety of analyzers which carry out static analysis of your code and warn you about things which might be wrong but won’t be picked up by the compiler —such as unreachable code, unnecessary assignments, and badly-formed build tags.
- Use the third-party [staticcheck](https://staticcheck.dev/) tool to carry out some additional static analysis checks.
- Use the `go test -race -vet=off ./...` command to run all tests in the project directory. By default, go test automatically executes a small subset of the `go vet` checks before running any tests, so to avoid duplication we’ll use the `-vet=off` flag to turn this off. The `-race` flag enables Go’s [race detector](https://go.dev/doc/articles/race_detector), which can help pick up certain classes of race conditions while tests are running.

In contrast, the `tidy` rule will actually make changes to the codebase. It will:

- Use the `go fmt ./...` command to format all `.go` files in the project directory, according to the Go standard. This will reformat files ‘in place’ and output the names of any changed files.
- Use the `go mod tidy` command to prune any unused dependencies from the `go.mod` and `go.sum` files, and add any missing dependencies.

```makefile
# File: Makefile 

# ================================================================================== #
# HELPERS 
# ================================================================================== #


## help: print this help message 
.PHONY: help 
help:  
	@echo 'Usage:'  
	@sed -n 's/^##//p' ${MAKEFILE_LIST} | column -t -s ':' 
	
.PHONY: confirm 
confirm:  
	@echo -n 'Are you sure? [y/N] ' && read ans && [ $${ans:-N} = y ] 
	

# ================================================================================== #
# DEVELOPMENT 
# ================================================================================== #


## run/api: run the cmd/api application 
.PHONY: run/api 
run/api:  
	@go run ./cmd/api -db-dsn=${GREENLIGHT_DB_DSN} 
	
## db/psql: connect to the database using psql 
.PHONY: db/psql 
db/psql:  
	psql ${GREENLIGHT_DB_DSN} 
	
## db/migrations/new name=$1: create a new database migration 
.PHONY: db/migrations/new  
db/migrations/new:  
	@echo 'Creating migration files for ${name}...'  
	migrate create -seq -ext=.sql -dir=./migrations ${name} 
	
## db/migrations/up: apply all up database migrations 
.PHONY: db/migrations/up 
db/migrations/up: confirm  
	@echo 'Running up migrations...'  
	migrate -path ./migrations -database ${GREENLIGHT_DB_DSN} up 
	

# ================================================================================== #
# QUALITY CONTROL 
# ================================================================================== #


## tidy: format all .go files and tidy module dependencies 
.PHONY: tidy 
tidy:  
	@echo 'Formatting .go files...'  
	go fmt ./...
	@echo 'Tidying module dependencies...'  
	go mod tidy 
	
## audit: run quality control checks 
.PHONY: audit 
audit:  
	@echo 'Checking module dependencies'  
	go mod verify  
	@echo 'Vetting code...'  
	go vet ./...
	staticcheck ./...
	@echo 'Running tests...'  
	go test -race -vet=off ./...
```

### Module Proxies and Vendoring

#### Module proxies

Run the `go env` command to print out the settings for your Go operating environment. You can see the `GOPROXY` setting:

```
GOPROXY="https://proxy.golang.org,direct"
```

The URL `https://proxy.golang.org` that we see here points to a module mirror maintained by the Go team at Google

Whenever you fetch a package using the `go` command — either with `go get` or one of the `go mod *` commands — it will first attempt to retrieve the source code from this mirror.

If the mirror can’t fetch the code at all, then it will return an error response and the `go` tool will fall back to fetching a copy directly from the authoritative repository (thanks to the `direct` directive in the `GOPROXY` setting).

But if you don’t want to use the module mirror provided by Google, or you’re behind a firewall that blocks it, there are other alternatives like `https://goproxy.io` and the Microsoft-provided `https://athens.azurefd.net` that you can try instead. Or you can even host your own module mirror using the open-source [Athens](https://github.com/gomods/athens) and [goproxy](https://github.com/goproxy/goproxy) projects.

For example, if you wanted to switch to using `https://goproxy.io` as the primary mirror, then fall back to using `https://proxy.golang.org` as a secondary mirror, then fall back to a `direct` fetch, you could update your `GOPROXY` setting like so:

```
$ export GOPROXY=https://goproxy.io,https://proxy.golang.org,direct
```

Or if you want to disable module mirrors altogether, you can simply set the value to `direct` like so:

```
$ export GOPROXY=direct
```

#### Vendoring

```makefile
# File: Makefile 

...

# ================================================================================== #
# QUALITY CONTROL 
# ================================================================================== #


## tidy: format all .go files, and tidy and vendor module dependencies 
.PHONY: tidy 
tidy:  
	@echo 'Formatting .go files...'  
	go fmt ./...
	@echo 'Tidying module dependencies...'  
	go mod tidy  
	@echo 'Verifying and vendoring module dependencies...'  
	go mod verify  
	go mod vendor 
	
	...
```

- The `go mod tidy` command will make sure the `go.mod` and `go.sum` files list all the necessary dependencies for our project (and no unnecessary ones).
- The `go mod verify` command will verify that the dependencies stored in your module cache (located on your machine at `$GOPATH/pkg/mod`) match the cryptographic hashes in the `go.sum` file.
- The `go mod vendor` command will then copy the necessary source code from your module cache into a new `vendor` directory in your project root.

Now, when you run a command such as `go run`, `go test` or `go build`, the `go` tool will recognize the presence of a `vendor` folder and the dependency code in the vendor folder will be used — rather than the code in the module cache on your local machine.

**Note**: If you want to confirm that it’s really the vendored dependencies being used, you can run `go clean -modcache`  to remove everything from your local module cache.
When you run the API again, you should find that it still starts up correctly without needing to re-fetch the dependencies from the Go module mirror.

**Note**: It’s important to point out that there’s no easy way to verify that the checksums of the vendored dependencies match the checksums in the `go.sum` file. Or, in other words, there’s no equivalent to `go mod verify` which works directly on the contents of the `vendor` folder. To mitigate that, it’s a good idea to run both `go mod verify` and `go mod vendor` regularly — which is one of the reasons for including them both as part of the `make tidy` rule. Using `go mod verify` will verify that the dependencies in your module cache match the `go.sum` file, and `go mod vendor` will copy those same dependencies from the module cache into your `vendor` folder.

Lastly, you should avoid making any changes to the code in the `vendor` directory. Doing so can potentially cause confusion (because the code would no longer be consistent with the original version of the source code) and — besides — running `go mod vendor` will overwrite any changes you make each time you run it. If you need to change the code for a dependency, it’s far better to fork it and import the forked version instead.

#### Vendoring new dependencies

In the next section of the book we’re going to deploy our API application to the internet with [Caddy](https://caddyserver.com/) as a reverse-proxy in-front of it. This means that, as far as our API is concerned, all the requests it receives will be coming from a single IP address (the one running the Caddy instance). In turn, that will cause problems for our rate limiter middleware which limits access based on IP address.

Fortunately, like most other reverse proxies, Caddy adds an `X-Forwarded-For` header to each request. This header will contain the real IP address for the client.

Although we could write the logic to check for the presence of an `X-Forwarded-For` header and handle it ourselves, I recommend using the [realip](https://github.com/tomasen/realip) package to help with this. This package retrieves the client IP address from any `X-Forwarded-For` or `X-Real-IP` headers, falling back to use `r.RemoteAddr` if neither of them are present.

```
$ go get github.com/tomasen/realip@latest
```



```go
// File: cmd/api/middleware.go 

package main

import (  
  "errors"  
  "expvar"    
  "fmt"   
  "net/http" 
  "strconv"   
  "strings" 
  "sync"   
  "time"  
  
  "greenlight.alexedwards.net/internal/data" 
  "greenlight.alexedwards.net/internal/validator"   
  
  "github.com/tomasen/realip" // New import   
  "golang.org/x/time/rate" 
)

...

func (app *application) rateLimit(next http.Handler) http.Handler {  
  
  ...
  
  return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {   
    if app.config.limiter.enabled {   
      // Use the realip.FromRequest() function to get the client's real IP address.
      ip := realip.FromRequest(r)   
      
      mu.Lock()      
      
      if _, found := clients[ip]; !found {   
        clients[ip] = &client{  
          limiter: rate.NewLimiter(rate.Limit(app.config.limiter.rps), app.config.limiter.burst),           
        }       
      }   
      
      clients[ip].lastSeen = time.Now()  
      
      if !clients[ip].limiter.Allow() {      
        mu.Unlock()        
        app.rateLimitExceededResponse(w, r)  
        return     
      }      
      
      mu.Unlock()     
    }      
    
    next.ServeHTTP(w, r)  
  })
}

...
```

#### Additional Information

##### The ./… pattern

Most of the `go` tools support the `./...` wildcard pattern, like `go fmt ./...` , `go vet ./...` and `go test ./...`. This pattern matches the current directory and all sub-directories, excluding the `vendor` directory.

### Building Binaries

Here we’re going to focus on explaining how to build an executable binary that you can distribute and run on other machines without needing the Go toolchain installed. 

To build a binary we need to use the `go build` command. As a simple example, usage looks like this:

```
$ go build -o=./bin/api ./cmd/api
```

```makefile
# File: Makefile 

...


# ================================================================================== #
# BUILD 
# ================================================================================== #


## build/api: build the cmd/api application 
.PHONY: build/api 
build/api:  
	@echo 'Building cmd/api...'  
	go build -o=./bin/api ./cmd/api
```

#### Reducing binary size

By running command `ls -l ./bin/api`, you can see the file size is 11MB. It’s possible to reduce the binary size by around 25% by instructing the Go linker to strip symbol tables and [DWARF](https://pkg.go.dev/debug/dwarf) debugging information from the binary. We can do this as part of the `go build` command by using the linker flag `-ldflags="-s"` as follows:

```makefile
# File: Makefile 

...


# ================================================================================== #
# BUILD 
# ================================================================================== #


## build/api: build the cmd/api application 
.PHONY: build/api 
build/api:  
	@echo 'Building cmd/api...'  
	go build -ldflags='-s' -o=./bin/api ./cmd/api
```

By doing this, the file size is reduced to 7MB.

It’s important to be aware that stripping out this information will make it harder to debug an executable using a tool like [Delve](https://github.com/go-delve/delve) or [gdb](https://www.sourceware.org/gdb/). But, generally, it’s not often that you’ll need to do this — and there’s even an [open proposal](https://github.com/golang/go/issues/26074) from Rob Pike to make omitting DWARF information the default behavior of the linker in the future.

**Note**: The linker flag `-ldflags='-s'` strips out both symbol tables and DWARF debugging information. If you want to only omit the DWARF debugging information, you can use the linker flag `-ldflags='-w'` instead. If you want to only omit the symbol table, you can use the flags `-ldflags='-s -w=0'`

#### Cross-compilation

To see a list of all the operating system/architecture combinations that Go supports, you can run the `go tool dist list` command like so:

```
$ go tool dist list

aix/ppc64
android/386
android/amd64
android/arm
android/arm64
darwin/amd64
darwin/arm64
dragonfly/amd64
freebsd/386
freebsd/amd64
freebsd/arm
freebsd/arm64
freebsd/riscv64
illumos/amd64
ios/amd64
ios/arm64
js/wasm
linux/386
linux/amd64
linux/arm
linux/arm64
linux/loong64
linux/mips
linux/mips64
linux/mips64le
linux/mipsle
linux/ppc64
linux/ppc64le
linux/riscv64
linux/s390x
netbsd/386
netbsd/amd64
netbsd/arm
netbsd/arm64
openbsd/386
openbsd/amd64
openbsd/arm
openbsd/arm64
openbsd/ppc64
plan9/386
plan9/amd64
plan9/arm
solaris/amd64
wasip1/wasm
windows/386
windows/amd64
windows/arm
windows/arm64
```

And you can specify the operating system and architecture that you want to create the binary for by setting `GOOS` and `GOARCH` environment variables when running `go build`. For example:

```
$ GOOS=linux GOARCH=amd64 go build {args}
```

Let’s update our `make build/api` rule:

```makefile
# File: Makefile 

...


# ================================================================================== #
# BUILD 
# ================================================================================== #


## build/api: build the cmd/api application 
.PHONY: build/api 
build/api:  
	@echo 'Building cmd/api...'  
	go build -ldflags='-s' -o=./bin/api ./cmd/api
	GOOS=linux GOARCH=amd64 go build -ldflags='-s' -o=./bin/linux_amd64/api ./cmd/api
```

#### Additional Information

##### Build caching

It’s important to note that the `go build` command caches build output in the Go build cache. This cached output will be reused again in future builds where appropriate, which can significantly speed up the overall build time for your application. 

If you’re not sure where your build cache is, you can check by running the `go env GOCACHE` command.

You should also be aware that the build cache does not automatically detect any changes to C libraries that your code imports with [cgo](https://pkg.go.dev/cmd/cgo). So, if you’ve changed a C library since the last build, you’ll need to use the `-a` flag to force all packages to be rebuilt when running `go build`. Alternatively, you could use `go clean` to purge the cache:

```sh
$ go build -a -o=/bin/foo ./cmd/foo        # Force all packages to be rebuilt 
$ go clean -cache                          # Remove everything from the build cache
```

**Note**: If you ever run `go build` on a non-`main` package, the build output will be stored in the build cache so it can be reused, but no executable will be produced.

### Managing and Automating Version Numbers

#### Displaying the version number

Let’s start by updating our application so that we can easily check the version number by running the binary with a `-version` command-line flag, similar to this:

```
$ ./bin/api -version
```

