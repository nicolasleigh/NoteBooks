## Deployment and Hosting

### Creating a Digital Ocean Droplet

#### Creating a SSH key

```sh
$ ssh-keygen -t rsa -b 4096 -C "greenlight@greenlight.alexedwards.net" -f $HOME/.ssh/id_rsa_greenlight
```

And if you run the `ssh-add -l`  command, you should see your new SSH key listed in the output, similar to this:

```
$ ssh-add -l 
4096 SHA256:MXASjIyE1p2BAGZ70zkUV058rA65hm3sxdIcnWLGkwg greenlight@greenlight.alexedwards.net (RSA)
```

If you don’t see your key listed, then please add it to your SSH agent like so:

```
$ ssh-add $HOME/.ssh/id_rsa_greenlight
```

#### Adding the SSH key to Digital Ocean

### Server Configuration and Installing Software

```sh
# File: remote/setup/01.sh 

#!/bin/bash 
# When a query returns a non-zero status, the -e flag stops the script.
# The -u option prevents Bash from ignoring the non-existent variable.
# Check it out: https://www.baeldung.com/linux/set-command
set -eu 

# ================================================================================== #
# VARIABLES 
# ================================================================================== #

# Set the timezone for the server. A full list of available timezones can be found by
# running timedatectl list-timezones.
TIMEZONE=Europe/Berlin 

# Set the name of the new user to create.
USERNAME=greenlight 

# Prompt to enter a password for the PostgreSQL greenlight user (rather than 
# hard-coding a password in this script) and put it in the DB_PASSWORD variable.
# –p means to print the prompt text. 
# Check it out: https://www.baeldung.com/linux/read-command
read -p "Enter password for greenlight DB user: " DB_PASSWORD 

# Force all output to be presented in en_US for the duration of this script. This 
# avoids any "setting locale failed" errors while this script is running, before we 
# have installed support for all locales. Do not change this setting! 
export LC_ALL=en_US.UTF-8 

# ================================================================================== #
# SCRIPT LOGIC 
# ================================================================================== #

# Enable the "universe" repository.
add-apt-repository --yes universe 

# Update all software packages.
apt update 

# Set the system timezone and install all locales.
timedatectl set-timezone ${TIMEZONE} 
apt --yes install locales-all 

# Add the new user (and give them sudo privileges).
useradd --create-home --shell "/bin/bash" --groups sudo "${USERNAME}" 

# Force a password to be set for the new user the first time they log in.
passwd --delete "${USERNAME}" 
chage --lastday 0 "${USERNAME}" 

# Copy the SSH keys from the root user to the new user.
rsync --archive --chown=${USERNAME}:${USERNAME} /root/.ssh /home/${USERNAME} 

# Configure the firewall to allow SSH, HTTP and HTTPS traffic.
ufw allow 22 
ufw allow 80/tcp 
ufw allow 443/tcp 
ufw --force enable 

# Install fail2ban.
apt --yes install fail2ban 

# Install the migrate CLI tool.
curl -L https://github.com/golang-migrate/migrate/releases/download/v4.14.1/migrate.linux-amd64.tar.gz | tar xvz 
mv migrate.linux-amd64 /usr/local/bin/migrate 

# Install PostgreSQL.
apt --yes install postgresql 

# Set up the greenlight DB and create a user account with the password entered 
# earlier.
sudo -i -u postgres psql -c "CREATE DATABASE greenlight" 
sudo -i -u postgres psql -d greenlight -c "CREATE EXTENSION IF NOT EXISTS citext" 
sudo -i -u postgres psql -d greenlight -c "CREATE ROLE greenlight WITH LOGIN PASSWORD '${DB_PASSWORD}'" 

# Add a DSN for connecting to the greenlight database to the system-wide environment 
# variables in the /etc/environment file.
echo "GREENLIGHT_DB_DSN='postgres://greenlight:${DB_PASSWORD}@localhost/greenlight'" >> /etc/environment 

# Install Caddy (see https://caddyserver.com/docs/install#debian-ubuntu-raspbian).
apt install -y debian-keyring debian-archive-keyring apt-transport-https curl
curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg
curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list
apt update 
apt --yes install caddy 

# Upgrade all packages. Using the --force-confnew flag means that configuration 
# files will be replaced if newer ones are available.
apt --yes -o Dpkg::Options::="--force-confnew" upgrade 

echo "Script complete! Rebooting..." 
reboot
```

Send this bash file to the remote server:

```sh
$ rsync -rP --delete ./remote/setup nicolas@161.35.71.158:/home/nicolas 
```

**Note**: In this rsync command the -r flag indicates that we want to copy the contents of ./remote/setup recursively, the -P flag indicates that we want to display progress of the transfer, and the --delete flag indicates that we want to delete any extraneous files from destination directory on the droplet.

Run the bash script:

```sh
$ bash ~/setup/01.sh
```

Now, in the remote server, you can do the following checks:

```sh
$ migrate -version
```

```sh
$ psql $GREENLIGHT_DB_DSN
```

```sh
$ sudo systemctl status caddy
```

Go to `http://<your_server_ip>`, and you should see the Caddy welcome page.

#### Connecting to the droplet

```makefile
# File: Makefile 

...


# ================================================================================== #
# PRODUCTION 
# ================================================================================== #

production_host_ip = '161.35.71.158' 

## production/connect: connect to the production server 
.PHONY: production/connect 
production/connect:  
	ssh greenlight@${production_host_ip}
```

Now you can type `make production/connect` to connect your server

#### Additional Information

##### Future changes to the droplet configuration

If you need to make further changes to your droplet configuration or settings, you can create an additional `remote/setup/02.sh` script and then execute it in the following way:

```sh
$ rsync -rP --delete ./remote/setup greenlight@161.35.71.158:~ 
$ ssh -t greenlight@161.35.71.158 "sudo bash /home/greenlight/setup/02.sh"
```

### Deployment and Executing Migrations

```makefile
# File: Makefile 

...

# ================================================================================== #
# PRODUCTION 
# ================================================================================== #

production_host_ip = "161.35.71.158"

## production/connect: connect to the production server 
.PHONY: production/connect 
production/connect:  
	ssh greenlight@${production_host_ip} 
	
## production/deploy/api: deploy the api to production 
.PHONY: production/deploy/api 
production/deploy/api:  
	rsync -P ./bin/linux_amd64/api greenlight@${production_host_ip}:~  
	rsync -rP --delete ./migrations greenlight@${production_host_ip}:~  
	ssh -t greenlight@${production_host_ip} 'migrate -path ~/migrations -database $$GREENLIGHT_DB_DSN up'
```

Because the `$` character has a special meaning in makefiles, we are escaping it in the command above by prefixing it with an additional dollar character like `$$`.

It’s also important to note that we’re surrounding this command with single quotes. If we used double quotes, it would be an interpreted string and we would need to use an additional escape character `\` like so:

```
"migrate -path ~/migrations -database \$$GREENLIGHT_DB_DSN up"
```

#### Running the API

While we’re connected to the droplet, let’s try running the api executable binary. We can’t listen for incoming connections on port 80 because Caddy is already using this, so we’ll listen on the unrestricted port 4000 instead.

Allow 4000 port:

```
$ sudo ufw allow 4000/tcp
```

```
$ ./api -port=4000 -db-dsn=$GREENLIGHT_DB_DSN -env=production
```

### Running the API as a Background Service

n order to run our API application as a background service, the first thing we need to do is make a [unit file](https://www.freedesktop.org/software/systemd/man/latest/systemd.unit.html), which informs systemd how and when to run the service.

```sh
# File: remote/production/api.service 

[Unit] 
# Description is a human-readable name for the service.
Description=Greenlight API service 

# Wait until PostgreSQL is running and the network is "up" before starting the service.
After=postgresql.service 
After=network-online.target 
Wants=network-online.target 

# Configure service start rate limiting. If the service is (re)started more than 5 
# times in 600 seconds then don't permit it to start anymore.
StartLimitIntervalSec=600 
StartLimitBurst=5 

[Service] 
# Execute the API binary as the greenlight user, loading the environment variables 
# from /etc/environment and using the working directory /home/greenlight.
Type=exec 
User=greenlight 
Group=greenlight 
EnvironmentFile=/etc/environment 
WorkingDirectory=/home/greenlight 
ExecStart=/home/greenlight/api -port=4000 -db-dsn=${GREENLIGHT_DB_DSN} -env=production 

# Automatically restart the service after a 5-second wait if it exits with a non-zero 
# exit code. If it restarts more than 5 times in 600 seconds, then the rate limit we 
# configured above will be hit and it won't be restarted anymore.
Restart=on-failure 
RestartSec=5 

[Install] 
# Start the service automatically at boot time (the 'multi-user.target' describes a 
# boot state when the system will accept logins, it’s common to use this target 
# when we create a custom service). 
# Check it out: https://www.baeldung.com/linux/systemd-target-multi-user
WantedBy=multi-user.target
```

Now that we’ve got a unit file set up, the next step is to install this unit file on our droplet and start up the service. Essentially we need to do three things: 

1. To install the unit file, we need to copy it into the `/etc/systemd/system/` folder on our droplet. Because this folder is owned by the `root` user on our droplet, we need break this down into two steps: first we need to copy the unit file into the `greenlight` user’s home directory, and secondly use the `sudo mv` command to move it to its final location. 
2. Then we need to run the `systemctl enable api` command on our droplet to make `systemd` aware of the new unit file and automatically enable the service when the droplet is rebooted. 
3. Finally, we need to run `systemctl restart api` to start (or restart) the service.

```makefile
# File: Makefile 

...

# ================================================================================== 
# # PRODUCTION 
# ================================================================================== #

production_host_ip = '161.35.71.158'

...

## production/deploy/api: deploy the api to production 
.PHONY: production/deploy/api 
production/deploy/api: 
	rsync -P ./bin/linux_amd64/api greenlight@${production_host_ip}:~  
	rsync -rP --delete ./migrations greenlight@${production_host_ip}:~  
	rsync -P ./remote/production/api.service greenlight@${production_host_ip}:~  
	ssh -t greenlight@${production_host_ip} 'migrate -path ~/migrations -database $$GREENLIGHT_DB_DSN up && sudo mv ~/api.service /etc/systemd/system/ && sudo systemctl enable api && sudo systemctl restart api'
```

```
$ make production/deploy/api
$ make production/connect
$ sudo systemctl status api

 api.service - Greenlight API service
     Loaded: loaded (/etc/systemd/system/api.service; enabled; vendor preset: e>
     Active: active (running) since Tue 2024-12-10 16:40:15 CST; 4min 19s ago
   Main PID: 1906 (api)
      Tasks: 7 (limit: 2172)
     Memory: 1.7M
        CPU: 16ms
     ...
```

```
$ ps -U nicolas
		PID TTY          TIME CMD
    963 ?        00:00:00 systemd
    964 ?        00:00:00 (sd-pam)
    988 ?        00:00:00 sshd
    989 pts/0    00:00:00 bash
   1906 ?        00:00:00 api
   1974 ?        00:00:00 sshd
   1975 pts/1    00:00:00 bash
   1988 pts/1    00:00:00 sudo
   2115 pts/0    00:00:00 less
   2152 ?        00:00:00 sshd
   2153 pts/2    00:00:00 bash
   2168 pts/2    00:00:00 ps
```

#### Disable port 4000

```
$ sudo ufw delete allow 4000/tcp
```

#### Additional Information

##### Listening on a restricted port

If you’re not planning to run your application behind a reverse proxy, and want to listen for requests directly on port 80 or 443, you’ll need to set up your unit file so that the service has the `CAP_NET_BIND_SERVICE` capability (which will allow it to bind to a restricted port). For example:

```
[Unit] 
Description=Greenlight API service 

After=postgresql.service 
After=network-online.target 
Wants=network-online.target 

StartLimitIntervalSec=600 
StartLimitBurst=5 

[Service] 
Type=exec 
User=greenlight 
Group=greenlight 
CapabilityBoundingSet=CAP_NET_BIND_SERVICE 
AmbientCapabilities=CAP_NET_BIND_SERVICE 
EnvironmentFile=/etc/environment 
WorkingDirectory=/home/greenlight 
ExecStart=/home/greenlight/api -port=80 -db-dsn=${GREENLIGHT_DB_DSN} -env=production

Restart=on-failure 
RestartSec=5 

[Install] 
WantedBy=multi-user.target
```

##### Viewing logs

It’s possible to view the logs for your background service using the `journalctl` command, like so:

```
$ sudo journalctl -u api
```

Check this out: [How To Use Journalctl to View and Manipulate Systemd Logs](https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs)

##### Configuring the SMTP provider

It’s important to remember that apart from the port, db-dsn and env flags that we’re specifying here, our application will still be using the default values for the other settings which are hardcoded into the cmd/api/main.go file — including the SMTP credentials for your Mailtrap inbox. Under normal circumstances, you would want to set your production SMTP credentials as part of this command in the unit file too.

##### Additional unit file options

Systemd unit files offer a huge range of configuration options, and we’ve only just scratched the surface in this chapter. For more information, the [Understanding Systemd Units and Unit Files](https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files) article is a really good overview, and you can find comprehensive (albeit dense) information in the [man pages](https://www.freedesktop.org/software/systemd/man/latest/systemd.service.html). 

There is also [this gist](https://gist.github.com/ageis/f5595e59b1cddb1513d1b425a323db04) which talks through the various security options that you can use to help harden your service.

### Using Caddy as a Reverse Proxy

The simplest way to configure Caddy is to create a Caddyfile — which contains a series of rules describing what we want Caddy to do.

```
# File: remote/production/Caddyfile 

http://161.35.71.158 {  
	reverse_proxy localhost:4000 
}
```

More Caddyfile info: [The Official Docs](https://caddyserver.com/docs/caddyfile)

Update our `production/deploy/api` rule: copy our Caddyfile to `/etc/caddy/Caddyfile` on the server.

```makefile
# File: Makefile 

...

# ================================================================================== 
# # PRODUCTION 
# ================================================================================== #

production_host_ip = '161.35.71.158'

...

## production/deploy/api: deploy the api to production 
.PHONY: production/deploy/api 
production/deploy/api: 
	rsync -P ./bin/linux_amd64/api greenlight@${production_host_ip}:~  
	rsync -rP --delete ./migrations greenlight@${production_host_ip}:~  
	rsync -P ./remote/production/api.service greenlight@${production_host_ip}:~  
	rsync -P ./remote/production/Caddyfile greenlight@${production_host_ip}:~
	ssh -t greenlight@${production_host_ip} 'migrate -path ~/migrations -database $$GREENLIGHT_DB_DSN up && sudo mv ~/api.service /etc/systemd/system/ && sudo systemctl enable api && sudo systemctl restart api && sudo mv ~/Caddyfile /etc/caddy/ && sudo systemctl reload caddy'
```

#### Blocking access to application metrics

Now, everyone can navigate to the `GET /debug/vars` endpoint. It’s easy to block access to this by adding a new [respond](https://caddyserver.com/docs/caddyfile/directives/respond) directive to our Caddyfile like so:

```
# File: remote/production/Caddyfile 

http://161.35.71.158 {   
	respond /debug/* "Not Permitted" 403 
  reverse_proxy localhost:4000 
}
```

With this new directive we’re instructing Caddy to send a `403 Forbidden` response for all requests which have a URL path beginning `/debug/`.

Although the metrics are no longer publicly accessible, you can still access them by connecting to your droplet via SSH and making a request to `http://localhost:4000/debug/vars`.

```
$ make production/connect 
greenlight@greenlight-production:~$ curl http://localhost:4000/debug/vars
```

Or alternatively, you can open a SSH tunnel to the droplet and view them using a web browser on your local machine. For example, you could open an SSH tunnel between port 4000 on the droplet and port 9999 on your local machine by running the following command:

```sh
$ ssh -L 9999:localhost:4000 nicolas@106.14.126.186
```

Open the browser and type `http://localhost:9999/debug/vars`, you can see the debug page now!

#### Using a domain name

