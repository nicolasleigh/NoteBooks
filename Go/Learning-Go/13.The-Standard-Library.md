### io and Friends

```go
type Reader interface {    
  Read(p []byte) (n int, err error)
} 

type Writer interface {  
  Write(p []byte) (n int, err error)
}
```

If the `Read` method were written to return a `[]byte`, it would require a new allocation on every single call. Each allocation would end up on the heap, which would make quite a lot of work for the garbage collector.

If you want to reduce the allocations further, you could create a pool of buffers when the program launches. You would then take a buffer out of the pool when the function starts, and return it when it ends. By passing in a slice to `io.Reader`, memory allocation is under the control of the developer.

Second, you use the n value returned from `r.Read` to know how many bytes were written to the buffer and iterate over a subslice of your buf slice, processing the data that was read.

The `Read` method in `io.Reader` has one unusual aspect. In most cases when a function or method has an error return value, you check the error before you try to process the nonerror return values. You do the opposite for `Read` because bytes might have been copied into the buffer before an error was triggered by the end of the data stream or by an unexpected condition.

Because `io.Reader` and `io.Writer` are such simple interfaces, they can be implemented many ways. You can create an `io.Reader` from a string by using the `strings.NewReader` function.

```go
func countLetters(r io.Reader) (map[string]int, error) {
	buf := make([]byte, 2048)
	out := map[string]int{}
	for {
		n, err := r.Read(buf)
		for _, b := range buf[:n] {
			if (b >= 'A' && b <= 'Z') || (b >= 'a' && b <= 'z') {
				out[string(b)]++
			}
		}
		if err == io.EOF {
			return out, nil
		}
		if err != nil {
			return nil, err
		}
	}
}

func simpleCountLetters() error {
	s := "The quick brown fox jumped over the lazy dog"
	sr := strings.NewReader(s)
	counts, err := countLetters(sr)
	if err != nil {
		return err
	}
	fmt.Println(counts)
	return nil
}

func buildGZipReader(fileName string) (*gzip.Reader, func(), error) {
	r, err := os.Open(fileName)
	if err != nil {
		return nil, nil, err
	}
	gr, err := gzip.NewReader(r)
	if err != nil {
		return nil, nil, err
	}
	return gr, func() {
		gr.Close()
		r.Close()
	}, nil
}

func gzipCountLetters() error {
	r, closer, err := buildGZipReader("my_data.txt.gz")
	if err != nil {
		return err
	}
	defer closer()
	counts, err := countLetters(r)
	if err != nil {
		return err
	}
	fmt.Println(counts)
	return nil
}

func main() {
	err := simpleCountLetters()
	if err != nil {
		slog.Error("error with simpleCountLetters", "msg", err)
	}

	err = gzipCountLetters()
	if err != nil {
		slog.Error("error with gzipCountLetters", "msg", err)
	}
}

/*
map[T:1 a:1 b:1 c:1 d:2 e:4 f:1 g:1 h:2 i:1 j:1 k:1 l:1 m:1 n:1 o:4 p:1 q:1 r:2 t:1 u:2 v:1 w:1 x:1 y:1 z:1]
2024/10/30 13:31:35 ERROR error with gzipCountLetters msg="open my_data.txt.gz: no such file or directory"
*/
```

### time

Most operating systems keep track of two sorts of time: the wall clock, which corre‐sponds to the current time, and the monotonic clock, which counts up from the time the computer was booted. The reason for tracking two clocks is that the wall clock doesn’t uniformly increase. Daylight Saving Time, leap seconds, and Network Time Protocol (NTP) updates can make the wall clock move unexpectedly forward or backward. This can cause problems when setting a timer or finding the amount of time that’s elapsed.

To address this potential problem, Go uses monotonic time to track elapsed time whenever a timer is set or a time.Time instance is created with time.Now. This support is invisible; timers use it automatically. The Sub method uses the monotonic clock to calculate the time.Duration if both time.Time instances have it set. If they don’t (because one or both of the instances was not created with time.Now), the Sub method uses the time specified in the instances to calculate the time.Duration instead.

### encoding/json

```go
func main() {
	err := ProcessPerson()
	if err != nil {
		slog.Error("error in processPerson", "msg", err)
	}
}

type Person struct {
	Name string `json:"name"`
	Age  int    `json:"age"`
}

func ProcessPerson() error {
	toFile := Person{
		Name: "Fred",
		Age:  40,
	}

	// Write it out
	tmpFile, err := os.CreateTemp(os.TempDir(), "sample-")
	if err != nil {
		return err
	}
	defer os.Remove(tmpFile.Name())
	err = json.NewEncoder(tmpFile).Encode(toFile)
	if err != nil {
		return err
	}
	err = tmpFile.Close()
	if err != nil {
		return err
	}

	// Read it back in again
	tmpFile2, err := os.Open(tmpFile.Name())
	if err != nil {
		return err
	}
	var fromFile Person
	err = json.NewDecoder(tmpFile2).Decode(&fromFile)
	if err != nil {
		return err
	}
	err = tmpFile2.Close()
	if err != nil {
		return err
	}
	fmt.Printf("%+v\n", fromFile)
	return nil
}

// {Name:Fred Age:40}
```

What do you do when you have multiple JSON structs to read or write at once? Our friends json.Decoder and json.Encoder can be used for these situations too.

```go
func main() {
	const data = `
		{"name": "Fred", "age": 40}
		{"name": "Mary", "age": 21}
		{"name": "Pat", "age": 30}
	`
	var t struct {
		Name string `json:"name"`
		Age  int    `json:"age"`
	}
	dec := json.NewDecoder(strings.NewReader(data))
	var b bytes.Buffer
	enc := json.NewEncoder(&b)
	for {
		err := dec.Decode(&t)
		if err != nil {
			if errors.Is(err, io.EOF) {
				break
			}
			panic(err)
		}
		fmt.Println(t)
		err = enc.Encode(t)
		if err != nil {
			panic(err)
		}
	}
	out := b.String()
	fmt.Println(out)
}

/*
{Fred 40}
{Mary 21}
{Pat 30}
{"name":"Fred","age":40}
{"name":"Mary","age":21}
{"name":"Pat","age":30}
*/
```

